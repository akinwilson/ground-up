{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.special import xlogy, xlog1py \n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "InteractiveShell.ast_node_interactive = \"all\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a system where:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h^t= f (h^{t-1},\\theta)  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta \\text{: parameters shared across all time steps}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, its state at time step t, is dependent only on a set a parameters and the previous state at t-1\n",
    "<br>\n",
    "<br>\n",
    "Let the state of the system, h, also be depedent on an input at the respective time step, x:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h^t= f (h^{t-1},x^{t},\\theta)  \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state h now contains information about the entire past history of inputs, x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider now a system that given the hidden state, h,produces an output o, for each time step. This output is passed to an activation function made to predict the target, y, at the respective time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "o^t= g (h^{t},\\theta')  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta' \\text{: a different set of parameters as $\\theta$}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define now define $\\theta$ and $\\theta'$ as the weight matrices describing the relation between the input-to-hidden, hidden-to-hidden and hidden-to-output notes; $U$, $W$ and $V$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "z^t=  W^{T}h^{t-1} + U^{T}x^t +b \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "h^{t} = \\phi(z^t)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "o^t = V^Th^{t} + c\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $b$ and $c$ are biases, $\\phi$ is an activation function. <br><br>\n",
    "**Note**: matrices $U$, $W$ and $V$ are not indexed by time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider the following schematic to get a better understanding for a reccurent system\n",
    "<img src=\"media/RNNFoldedandUnfolded.png\" style=\"height: 300px;\"/>\n",
    "credits: fdeloche "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each time step, we have a sequential total loss up to time step $\\tau$, $L^\\tau$, defined as the difference between our prediction and the target, at each output, upto the time step $\\tau$\n",
    "<br>\n",
    "<br>\n",
    "Consider the task of multi-class classification. \n",
    "<br>\n",
    "<br>\n",
    "Consequently, the output activation function is the normalized expontential function, a.k.a the _softmax function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L = \\sum_{t=1}^{\\tau} l\\big(o^{t}\\big)\n",
    "\\text{: Total loss upto time step $\\tau$}  \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}^t_i = \\frac{\\exp(o_i^t)}{\\sum_{j}\\exp(o_j^t)}\n",
    "\\text{: Softmax activation function for multi-class classification}\n",
    "\\end{equation}\n",
    "\n",
    "**NOTE** the softmax is a vector function, later when taking the derivative, in reality I am finding the Jacobian of it in its vector form, but here I denote one element of it, the $i^{th}$\n",
    "\n",
    "\\begin{equation}\n",
    "l = - \\sum_{m=0}^{M-1}y_{m}^{t} \\log\\Big(\\hat{y}_{m}^{t}\\Big)\n",
    "\\text{: M categorical cross entropy for predictions at time step $t$}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization process differs from standard back-propagation (like descirbed for a vanilla feedforward network). Usng the above assumptions, I will go through the derivation analogous optimization process for recurrent networks;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back propagation through time\n",
    "\n",
    "Per example loss w.r.t to the output element $o_i$ at time $t$; $o_i^{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{o_{i}^{t}} L = \\frac{\\partial{L}}{\\partial{l(o_i^t)}} \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}}\n",
    "\\end{equation}\n",
    "Note that:\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{L}}{\\partial{l(o_i^t)}} = 1\n",
    "\\end{equation}\n",
    "and that:\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}}\n",
    "\\end{equation}\n",
    "is the derivative of the categorical cross-entropy\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} \\frac{y_j^{t}}{\\hat{y}_j^{t}}\\frac{\\partial{\\hat{y}^{t}_j}}{\\partial{o_i^{t}}} } - [1]\n",
    "\\end{equation}\n",
    "The softmax functions is:\n",
    " \\begin{equation}\n",
    " \\hat{y}^t_i = \\frac{\\exp(o_i^t)}{\\sum_{j}\\exp(o_j^t)}\n",
    "\\end{equation}\n",
    "Taking its derivative gives:\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "    \\frac{\\partial{\\hat{y}^{t}_i}}{\\partial{o_j^{t}}} = \\hat{y}^{t}_{i} \\Big( \\delta_{ij}  -  \\hat{y}^{t}_{j} \\Big)\n",
    "}- [2]\n",
    "\\end{equation}\n",
    "_look at the different cases to see why this is true_ i.e. $i=j$ and $i \\neq j$\n",
    "<br><br>\n",
    "Lets sub [2] into [1], and splitting into the cases where $i=j$ and $i \\neq j $:\n",
    "\n",
    " \\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} \\frac{y_j^{t}}{\\hat{y}_j^{t}} \\hat{y}^{t}_{j} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation}\n",
    "\n",
    " \\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} y_j^{t} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation}\n",
    " \n",
    "Lets now split the sum up for the two cases;\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} \\Bigr|_{j=i} + \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} \\Bigr|_{j \\neq i}  =  -y^{t}_{i}(\\delta_{ii} - \\hat{y}_{i})^{t} - \\sum_{j \\neq i} y_j^{t} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation} \n",
    "Simplfying down: \n",
    "\n",
    "\\begin{equation}\n",
    " \n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  -y^{t}_{i}(1 - \\hat{y}_{i})^{t} - \\sum_{j \\neq i} y_j^{t} \\Big( 0 -\\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation} \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} y_j^{t} \\hat{y}^{t}_{i}  -y^{t}_{i}(1 - \\hat{y}_{i})^{t} \n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} y_j^{t} \\hat{y}^{t}_{i}+y^{t}_{i}\\hat{y}_{i}^{t}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "Recall that $\\sum_{j} y_j = 1$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} \\Big( y_j^{t} +y^{t}_{i} \\Big) \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j} \\Big( y_j^{t} \\Big) \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "}\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets calculate the gradient on the internel nodes $h^t$ from the end of the sequence $\\tau$.\n",
    "<br>\n",
    "I am going to use vector notation here on out. I.e. $h_i^{t}$ becomes $h^t$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^\\tau} L = \\Bigg( \\frac{ \\partial{o^{\\tau}}}\n",
    "{\\partial{h^{\\tau}}} \\Bigg)^{T} \\nabla_{o^\\tau} L\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{h^\\tau} L = V \\nabla_{o^\\tau} L\n",
    "\\end{equation}\n",
    "we iterate backwards through time. Note the dependency of $h^t$ on both $o^t$ and $h^{t+1}$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = \\Bigg( \\frac{ \\partial{h^{t+1}}}\n",
    "{\\partial{h^{t}}} \\Bigg)^{T} \\nabla_{h^{t+1}} L +\n",
    "\\Bigg( \\frac{ \\partial{o^{t}}}\n",
    "{\\partial{h^{t}}} \\Bigg)^{T} \\nabla_{o^{t}} L \n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivate of the hidden units  w.r.t their previous time step is:\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{ \\partial{h^{t+1}} }\n",
    "{\\partial{h^{t}} }  =  \\frac{ \\partial{h^{t+1}} }{ \\partial{z^{t+1} } }\n",
    "\\frac{ \\partial{z^{t+1} } } { \\partial{h^{t}} }\n",
    "\\end{equation}\n",
    "This leads to:\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{ \\partial{h^{t+1}} }\n",
    "{\\partial{h^{t}} }  =  diag\\Bigg( \\phi'\\big(z^{t+1}\\big) \\Bigg) W^T\n",
    "\\end{equation}\n",
    "**Note** diag: considering only the leading diagonal values and setting all others to 0. \n",
    "<br><br>\n",
    "For RNNs , we want to use a saturating activation to avoid gradient explosions <br><br>\n",
    "e.g. hyperbolic tagent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = W  diag \\Big( \\phi'\\big(z^{t+1}\\big) \\Big)   \\nabla_{h^{t+1}} L +\n",
    "V \\nabla_{o^{t}} L \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets specify the activation function (using the hyperpolic tagent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = W  diag \\Big( \n",
    "     1 - \\big(h^{t+1}\\big)^2\n",
    "    \\Big)  \\nabla_{h^{t+1}} L +\n",
    "V \\nabla_{o^{t}} L \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the gradients on the biases $b$ and $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{c} L  = \\sum_{t} \\Bigg(\n",
    "     \\frac{\\partial{o^t}}{\\partial{c^t}} \n",
    "     \\Bigg)^{T} \\nabla_{o^t} L\n",
    "\\end{equation}\n",
    "since $\\frac{\\partial{o^t}}{\\partial{c^t}} = 1$\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{c} L  = \\sum_{t} \\nabla_{o^t} L\n",
    "\\end{equation}\n",
    "Next:\n",
    "\\begin{equation}\n",
    "\\nabla_{b} L  = \\sum_{t}  \\Bigg(\n",
    "     \\frac{\\partial{h^t}}{\\partial{b^t}} \n",
    "     \\Bigg)^{T}  \\nabla_{h^t} L\n",
    "\\end{equation}\n",
    "Since $b$ is dependent on h through the activation function $\\phi$, we have: \n",
    "\n",
    "Next:\n",
    "\\begin{equation}\n",
    "\\nabla_{b} L  = \\sum_{t}  diag \\Bigg( \\phi' \\Big( z^t \\Big) \\Bigg) \\nabla_{h^t} L\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative w.r.t to $V$; the hidden-ouput matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{V} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial o_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{V} O_i^{t}\n",
    "\\end{equation}\n",
    "Leading to:\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{V} L  = \\sum_{t} h^t \\Big(\\nabla_{o^t} L \\Big)^T\n",
    "}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the derivative w.r.t the weight matrices $W$ and $U$, we introduce dummy variables $W^t$ and $U^t$. These are copies of each other at each time step, summing these up will give us the total gradient. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{W} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial h_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{W^t} h_i^{t}\n",
    "\\end{equation}\n",
    "giving: \n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{W} L  = \\sum_{t} h^{t-1} \\Big(\\nabla_{h^t} L \\Big)^T  diag \\Bigg( \\phi ' \\big(z^t \\big) \\Bigg)\n",
    "\n",
    "}\n",
    "\\end{equation}\n",
    "for the derivative of w.r.t $U$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{U} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial h_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{U^t} h_i^{t}\n",
    "\\end{equation}\n",
    "giving: \n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{U} L  = \\sum_{t} x^{t} \\Big( \\nabla_{h^t} L \\Big)^T \n",
    "     diag \\Bigg( \\phi ' \\big(z^t \\big) \\Bigg)\n",
    "\n",
    "}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network implementation with backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, idx2wave):\n",
    "        # network variables \n",
    "        self.idim = input_dim\n",
    "        self.hdim = hidden_dim\n",
    "        self.odim = output_dim\n",
    "        # initialise weights \n",
    "        self.U = np.random.uniform(- np.sqrt(1./self.idim),\n",
    "                                     np.sqrt(1./self.idim),\n",
    "                                    (self.idim, self.hdim) )\n",
    "\n",
    "        self.V = np.random.uniform( -np.sqrt(1./self.hdim),\n",
    "                                     np.sqrt(1./self.hdim), \n",
    "                                    (self.hdim,self.odim))\n",
    "\n",
    "        self.W = np.random.uniform( -np.sqrt(1./self.hdim),\n",
    "                                     np.sqrt(1./self.hdim), \n",
    "                                    (self.hdim,self.hdim))\n",
    "        # bias init \n",
    "        self.b = np.zeros(self.hdim)\n",
    "        self.c = np.zeros(self.odim)\n",
    "\n",
    "        self.idx2wave = idx2wave \n",
    "\n",
    "    def softmax(self,x):\n",
    "        '''\n",
    "        Note that this is a numerically stable version of softmax.\n",
    "        We substract the max value from all elements.\n",
    "        Overflow of a single element, or underflow of all elements,  will render the output usless.\n",
    "        subtracting max leaves only non-positive values ---> no overflow \n",
    "        at least one element = 0 ---> no vanishing denominator (underflow is some enteries is okay) \n",
    "         '''\n",
    "        xt = np.exp(x-np.max(x))\n",
    "        return xt / np.sum(xt)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Single example pass forward, all the way through the network\n",
    "        T = len(x)\n",
    "        # will stack as rows\n",
    "        h = np.zeros((T,self.hdim))\n",
    "        o = np.zeros((T,self.odim))\n",
    "        for t in range(T):\n",
    "            h[t] = self.U.T @ x[t] + self.b\n",
    "            if t > 1:\n",
    "                h[t] += self.W @ h[t-1] + self.b\n",
    "            h[t] = np.tanh(h[t])\n",
    "            o[t] = self.softmax( self.V.T @ h[t] + self.c)\n",
    "        return (o,h)\n",
    "\n",
    "\n",
    "\n",
    "    def backward(self, x, y, clip=None):\n",
    "        T = len(x)\n",
    "        o,h = self.forward(x)\n",
    "        dLdU = np.zeros(self.U.shape)\n",
    "        dLdV = np.zeros(self.V.shape)\n",
    "        dLdW = np.zeros(self.W.shape)\n",
    "        dLdb = np.zeros(self.b.shape)\n",
    "        dLdc = np.zeros(self.c.shape)\n",
    "        # dL/do\n",
    "        delta_o = o\n",
    "        # Notice, only evaluting at last output of network, yHat - y \n",
    "        delta_o[ np.arange(T), y ] -= float(y) \n",
    "        # dL/dh\n",
    "        delta_h = np.zeros((T, self.hdim))\n",
    "        for t in reversed(range(T)):\n",
    "\n",
    "            # collect errors on hidden states\n",
    "            delta_h[t] = self.V @ delta_o[T-1,:]\n",
    "            if t < T-1:\n",
    "                # collect errors on hidden states due to W\n",
    "                delta_h[t] = ( self.W @ np.diag(1-h[t+1]**2) ) @ delta_h[t+1]\n",
    "        for t in range(T):\n",
    "            # error on ouput bias\n",
    "            dLdc += delta_o[T-1,:]\n",
    "            # error on hidden bias \n",
    "            dLdb += (1-h[t]**2) * delta_h[t,:]\n",
    "            # error on hidden-output matrix\n",
    "            ot = delta_o[T-1,:][...,np.newaxis]\n",
    "            ht = h[t,:][...,np.newaxis]\n",
    "            dht = delta_h[t,:][...,np.newaxis]\n",
    "\n",
    "            dLdV += ht @ ot.T \n",
    "            # error on hidden-hidden W\n",
    "            if t > 0 :\n",
    "                h_t = h[t-1,:][...,np.newaxis]\n",
    "                dLdW += ( h_t @ dht.T )@np.diag(1-h[t]**2)\n",
    "            xt = x[t][...,np.newaxis]\n",
    "            dLdU += xt @ dht.T @ np.diag(1-h[t]**2)\n",
    "\n",
    "        if clip is not None:\n",
    "            dLdb = np.clip(dLdb, -clip, clip)\n",
    "            dLdc = np.clip(dLdc, -clip, clip)\n",
    "            dLdV = np.clip(dLdV, -clip, clip)\n",
    "            dLdW = np.clip(dLdW, -clip, clip)\n",
    "            dLdU = np.clip(dLdU, -clip, clip)\n",
    "        return (dLdU, dLdV, dLdW, dLdb, dLdc)\n",
    "\n",
    "\n",
    "    def step(self,x,y,lr=0.0001):\n",
    "        dLdU, dLdV, dLdW, dLdb, dLdc = self.backward(x,y)\n",
    "        self.U -= lr * dLdU\n",
    "        self.V -= lr * dLdV\n",
    "        self.W -= lr * dLdW \n",
    "        self.b -= lr * dLdb \n",
    "        self.c -= lr * dLdc \n",
    "    \n",
    "\n",
    "    def Loss(self, x,y):\n",
    "        o,h = self.forward(x)      \n",
    "        yHat= o[len(x)-1, :]\n",
    "        y_1h = [0.0]*len(yHat)\n",
    "        y_1h[int(y)] = 1.0\n",
    "        LOSS = self.categorical_cross_entropy_loss(yHat, y_1h)\n",
    "        return LOSS\n",
    "\n",
    "\n",
    "    def categorical_cross_entropy_loss(self, yHats, ys):\n",
    "        loss = 0.0\n",
    "        e =  1e-15 # adding to pred values for numerical stability\n",
    "        for pred,true in zip(yHats, ys):\n",
    "            loss += -1.0*(xlogy(true, pred+e) + xlog1py(1.0-true,-pred+e))\n",
    "        return loss\n",
    "\n",
    "    def predict(self,x):\n",
    "        o,_ = self.forward(x)\n",
    "        output = list(o[len(x)-1, :]) \n",
    "        return output.index(max(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling synthetic time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.linspace(-2*np.pi, 2*np.pi, 50)\n",
    "\n",
    "\n",
    "def noisy_sin_wave(x):\n",
    "    return np.sin(x*0.1) + np.random.normal(loc=0, scale=0.1)\n",
    "\n",
    "\n",
    "def noisy_cos_wave(x):\n",
    "    return np.cos(x*1.5) + np.random.normal(loc=0, scale=0.2)\n",
    "\n",
    "\n",
    "def noisy_tan_wave(x):\n",
    "    return np.tan(x) + np.random.normal(loc=0, scale=0.3)\n",
    "\n",
    "\n",
    "def plot_noisy_func(func, domain,title):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.set_title(title)\n",
    "    ax.plot(domain,np.vectorize(func)(domain), \".\")\n",
    "\n",
    "\n",
    "def create_sample_seq(func1, domain, label):\n",
    "    X = np.array([np.vectorize(func1)(domain)])\n",
    "    Y = np.array([label]*X.shape[0])\n",
    "    X = X.T\n",
    "    return X,Y\n",
    "\n",
    "plot_noisy_func(noisy_sin_wave, X, \"Noisy sin wave\")\n",
    "plot_noisy_func(noisy_cos_wave, X, \"Noisy cos wave\")\n",
    "plot_noisy_func(noisy_tan_wave, X, \"Noisy tan wave\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synthetic data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(domain, sample_size=50):\n",
    "    X0 = [ create_sample_seq(noisy_sin_wave, domain, 0) for _ in range(sample_size)]\n",
    "    X1 = [ create_sample_seq(noisy_cos_wave, domain, 1) for _ in range(sample_size)]\n",
    "    X2 = [ create_sample_seq(noisy_tan_wave, domain, 2) for _ in range(sample_size)]\n",
    "    X = [*X0, *X1 , *X2]\n",
    "    random.shuffle(X)\n",
    "    idx2wave = {0:\"sin\", 1:\"cos\", 2:\"tan\"}\n",
    "    return X, idx2wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c69db0d64e44b48b183edc1e2ff5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.16766808319030105\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "MAX_EPOCHS = 20\n",
    "LR=0.001\n",
    "domain = np.linspace(-2*np.pi, 2*np.pi, 50)\n",
    "X, idx2wave = data_loader(domain)\n",
    "\n",
    "model = RNN(input_dim=1, output_dim=3, hidden_dim=128, idx2wave=idx2wave)\n",
    "for epoch in tqdm(range(MAX_EPOCHS)):\n",
    "    loss = 0\n",
    "    for pair in X:\n",
    "        x,y  = pair        \n",
    "        loss += model.Loss(x, y)\n",
    "        model.step(x, y, lr=LR)\n",
    "        loss = loss / len(x)\n",
    "    print(f\"Epoch {epoch} Loss {loss}\")\n",
    "    loss_history.append(loss)\n",
    "    if loss < 1e-5:\n",
    "        print(\"*\"*20)\n",
    "        print(f\"Termination condition met at epoch: {epoch}.\")\n",
    "        print(\"*\"*20)\n",
    "        break \n",
    "\n",
    "\n",
    "\n",
    "X, idx2wave = data_loader(domain, sample_size=20)\n",
    "true, pred = [], []\n",
    "for idx in range(len(X)):\n",
    "    x, y = X[idx][0],X[idx][1]\n",
    "    out = model.predict(x)\n",
    "    true.append(list(y)[0])\n",
    "    pred.append(out)\n",
    "\n",
    "\n",
    "target_names = list(idx2wave.values())\n",
    "print(classification_report(true,pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "ground-up-Awl4p5GG",
   "language": "python",
   "name": "ground-up-awl4p5gg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
