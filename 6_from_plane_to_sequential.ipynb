{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import warnings\n",
    "import sympy as sy\n",
    "from scipy.special import xlogy, xlog1py \n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "InteractiveShell.ast_node_interactive = \"all\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a system where:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h^t= f (h^{t-1},\\theta)  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta \\text{: parameters shared across all time steps}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, its state at time step t, is dependent only on a set a parameters and the previous state at t-1\n",
    "<br>\n",
    "<br>\n",
    "Let the state of the system, h, also be depedent on an input at the respective time step, x:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h^t= f (h^{t-1},x^{t},\\theta)  \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state h now contains information about the entire past history of inputs, x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider now a system that given the hidden state, h,produces an output o, for each time step. This output is passed to an activation function made to predict the target, y, at the respective time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "o^t= g (h^{t},\\theta')  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta' \\text{: a different set of parameters as $\\theta$}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define now define $\\theta$ and $\\theta'$ as the weight matrices describing the relation between the input-to-hidden, hidden-to-hidden and hidden-to-output notes; $U$, $W$ and $V$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "z^t=  W^{T}h^{t-1} + U^{T}x^t +b \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "h^{t} = \\phi(z^t)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "o^t = V^Th^{t} + c\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $b$ and $c$ are biases, $\\phi$ is an activation function. <br><br>\n",
    "**Note**: matrices $U$, $W$ and $V$ are not indexed by time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider the following schematic to get a better understanding for a reccurent system\n",
    "<img src=\"media/RNNFoldedandUnfolded.png\" style=\"height: 300px;\"/>\n",
    "credits: fdeloche "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each time step, we have a sequential total loss up to time step $\\tau$, $L^\\tau$, defined as the difference between our prediction and the target, at each output, upto the time step $\\tau$\n",
    "<br>\n",
    "<br>\n",
    "Consider the task of multi-class classification. \n",
    "<br>\n",
    "<br>\n",
    "Consequently, the output activation function is the normalized expontential function, a.k.a the _softmax function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L = \\sum_{t=1}^{\\tau} l\\big(o^{t}\\big)\n",
    "\\text{: Total loss upto time step $\\tau$}  \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}^t_i = \\frac{\\exp(o_i^t)}{\\sum_{j}\\exp(o_j^t)}\n",
    "\\text{: Softmax activation function for multi-class classification}\n",
    "\\end{equation}\n",
    "\n",
    "**NOTE** the softmax is a vector function, later when taking the derivative, in reality I am finding the Jacobian of it in its vector form, but here I denote one element of it, the $i^{th}$\n",
    "\n",
    "\\begin{equation}\n",
    "l = - \\sum_{m=0}^{M-1}y_{m}^{t} \\log\\Big(\\hat{y}_{m}^{t}\\Big)\n",
    "\\text{: M categorical cross entropy for predictions at time step $t$}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization process differs from standard back-propagation (like descirbed for a vanilla feedforward network). Usng the above assumptions, I will go through the derivation analogous optimization process for recurrent networks;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back propagation through time\n",
    "\n",
    "Per example loss w.r.t to the output element $o_i$ at time $t$; $o_i^{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{o_{i}^{t}} L = \\frac{\\partial{L}}{\\partial{l(o_i^t)}} \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}}\n",
    "\\end{equation}\n",
    "Note that:\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{L}}{\\partial{l(o_i^t)}} = 1\n",
    "\\end{equation}\n",
    "and that:\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}}\n",
    "\\end{equation}\n",
    "is the derivative of the categorical cross-entropy\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} \\frac{y_j^{t}}{\\hat{y}_j^{t}}\\frac{\\partial{\\hat{y}^{t}_j}}{\\partial{o_i^{t}}} } - [1]\n",
    "\\end{equation}\n",
    "The softmax functions is:\n",
    " \\begin{equation}\n",
    " \\hat{y}^t_i = \\frac{\\exp(o_i^t)}{\\sum_{j}\\exp(o_j^t)}\n",
    "\\end{equation}\n",
    "Taking its derivative gives:\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "    \\frac{\\partial{\\hat{y}^{t}_i}}{\\partial{o_j^{t}}} = \\hat{y}^{t}_{i} \\Big( \\delta_{ij}  -  \\hat{y}^{t}_{j} \\Big)\n",
    "}- [2]\n",
    "\\end{equation}\n",
    "_look at the different cases to see why this is true_ i.e. $i=j$ and $i \\neq j$\n",
    "<br><br>\n",
    "Lets sub [2] into [1], and splitting into the cases where $i=j$ and $i \\neq j $:\n",
    "\n",
    " \\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} \\frac{y_j^{t}}{\\hat{y}_j^{t}} \\hat{y}^{t}_{j} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation}\n",
    "\n",
    " \\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} y_j^{t} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation}\n",
    " \n",
    "Lets now split the sum up for the two cases;\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} \\Bigr|_{j=i} + \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} \\Bigr|_{j \\neq i}  =  -y^{t}_{i}(\\delta_{ii} - \\hat{y}_{i})^{t} - \\sum_{j \\neq i} y_j^{t} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation} \n",
    "Simplfying down: \n",
    "\n",
    "\\begin{equation}\n",
    " \n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  -y^{t}_{i}(1 - \\hat{y}_{i})^{t} - \\sum_{j \\neq i} y_j^{t} \\Big( 0 -\\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation} \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} y_j^{t} \\hat{y}^{t}_{i}  -y^{t}_{i}(1 - \\hat{y}_{i})^{t} \n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} y_j^{t} \\hat{y}^{t}_{i}+y^{t}_{i}\\hat{y}_{i}^{t}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "Recall that $\\sum_{j} y_j = 1$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} \\Big( y_j^{t} +y^{t}_{i} \\Big) \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j} \\Big( y_j^{t} \\Big) \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "}\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets calculate the gradient on the internel nodes $h^t$ from the end of the sequence $\\tau$.\n",
    "<br>\n",
    "I am going to use vector notation here on out. I.e. $h_i^{t}$ becomes $h^t$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^\\tau} L = \\Bigg( \\frac{ \\partial{o^{\\tau}}}\n",
    "{\\partial{h^{\\tau}}} \\Bigg)^{T} \\nabla_{o^\\tau} L\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{h^\\tau} L = V \\nabla_{o^\\tau} L\n",
    "\\end{equation}\n",
    "we iterate backwards through time. Note the dependency of $h^t$ on both $o^t$ and $h^{t+1}$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = \\Bigg( \\frac{ \\partial{h^{t+1}}}\n",
    "{\\partial{h^{t}}} \\Bigg)^{T} \\nabla_{h^{t+1}} L +\n",
    "\\Bigg( \\frac{ \\partial{o^{t}}}\n",
    "{\\partial{h^{t}}} \\Bigg)^{T} \\nabla_{o^{t}} L \n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivate of the hidden units  w.r.t their previous time step is:\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{ \\partial{h^{t+1}} }\n",
    "{\\partial{h^{t}} }  =  \\frac{ \\partial{h^{t+1}} }{ \\partial{z^{t+1} } }\n",
    "\\frac{ \\partial{z^{t+1} } } { \\partial{h^{t}} }\n",
    "\\end{equation}\n",
    "This leads to:\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{ \\partial{h^{t+1}} }\n",
    "{\\partial{h^{t}} }  =  diag\\Bigg( \\phi'\\big(z^{t+1}\\big) \\Bigg) W^T\n",
    "\\end{equation}\n",
    "**Note** diag: considering only the leading diagonal values and setting all others to 0. \n",
    "<br><br>\n",
    "For RNNs , we want to use a saturating activation to avoid gradient explosions <br><br>\n",
    "e.g. hyperbolic tagent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = W  diag \\Big( \\phi'\\big(z^{t+1}\\big) \\Big)   \\nabla_{h^{t+1}} L +\n",
    "V \\nabla_{o^{t}} L \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets specify the activation function (using the hyperpolic tagent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = W  diag \\Big( \n",
    "     1 - \\big(h^{t+1}\\big)^2\n",
    "    \\Big)  \\nabla_{h^{t+1}} L +\n",
    "V \\nabla_{o^{t}} L \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the gradients on the biases $b$ and $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{c} L  = \\sum_{t} \\Bigg(\n",
    "     \\frac{\\partial{o^t}}{\\partial{c^t}} \n",
    "     \\Bigg)^{T} \\nabla_{o^t} L\n",
    "\\end{equation}\n",
    "since $\\frac{\\partial{o^t}}{\\partial{c^t}} = 1$\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{c} L  = \\sum_{t} \\nabla_{o^t} L\n",
    "\\end{equation}\n",
    "Next:\n",
    "\\begin{equation}\n",
    "\\nabla_{b} L  = \\sum_{t}  \\Bigg(\n",
    "     \\frac{\\partial{h^t}}{\\partial{b^t}} \n",
    "     \\Bigg)^{T}  \\nabla_{h^t} L\n",
    "\\end{equation}\n",
    "Since $b$ is dependent on h through the activation function $\\phi$, we have: \n",
    "\n",
    "Next:\n",
    "\\begin{equation}\n",
    "\\nabla_{b} L  = \\sum_{t}  diag \\Bigg( \\phi' \\Big( z^t \\Big) \\Bigg) \\nabla_{h^t} L\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative w.r.t to $V$; the hidden-ouput matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{V} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial o_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{V} O_i^{t}\n",
    "\\end{equation}\n",
    "Leading to:\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{V} L  = \\sum_{t} h^t \\Big(\\nabla_{o^t} L \\Big)^T\n",
    "}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the derivative w.r.t the weight matrices $W$ and $U$, we introduce dummy variables $W^t$ and $U^t$. These are copies of each other at each time step, summing these up will give us the total gradient. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{W} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial h_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{W^t} h_i^{t}\n",
    "\\end{equation}\n",
    "giving: \n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{W} L  = \\sum_{t} h^{t-1} \\Big(\\nabla_{h^t} L \\Big)^T  diag \\Bigg( \\phi ' \\big(z^t \\big) \\Bigg)\n",
    "\n",
    "}\n",
    "\\end{equation}\n",
    "for the derivative of w.r.t $U$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{U} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial h_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{U^t} h_i^{t}\n",
    "\\end{equation}\n",
    "giving: \n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{U} L  = \\sum_{t} x^{t} \\Big( \\nabla_{h^t} L \\Big)^T \n",
    "     diag \\Bigg( \\phi ' \\big(z^t \\big) \\Bigg)\n",
    "\n",
    "}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network implementation with backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128):\n",
    "        # network variables \n",
    "        self.idim = input_dim\n",
    "        self.hdim = hidden_dim\n",
    "        self.odim = output_dim\n",
    "        # initialise weights \n",
    "        self.U = np.random.uniform(- np.sqrt(1./self.idim),\n",
    "                                     np.sqrt(1./self.idim),\n",
    "                                    (self.idim, self.hdim) )\n",
    "\n",
    "        self.V = np.random.uniform( -np.sqrt(1./self.hdim),\n",
    "                                     np.sqrt(1./self.hdim), \n",
    "                                    (self.hdim,self.odim))\n",
    "\n",
    "        self.W = np.random.uniform( -np.sqrt(1./self.hdim),\n",
    "                                     np.sqrt(1./self.hdim), \n",
    "                                    (self.hdim,self.hdim))\n",
    "\n",
    "        self.b = np.zeros(self.hdim)\n",
    "        self.c = np.zeros(self.odim)\n",
    "    \n",
    "\n",
    "    def softmax(self,x):\n",
    "        '''\n",
    "        Note that this is a numerically stable version of softmax.\n",
    "        We substract the max value from all elements.\n",
    "        Overflow of a single element, or underflow of all elements,  will render the output usless.\n",
    "        subtracting max leaves only non-positive values ---> no overflow \n",
    "        at least one element = 0 ---> no vanishing denominator (underflow is some enteries is okay) \n",
    "         '''\n",
    "        xt = np.exp(x-np.max(x))\n",
    "        return xt / np.sum(xt)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Single example pass forward, all the way through the network\n",
    "        T = len(x)\n",
    "        # will stack as rows\n",
    "        h = np.zeros((T,self.hdim))\n",
    "        o = np.zeros((T,self.odim))\n",
    "        for t in range(T):\n",
    "            h[t] = self.U.T @ x[t] + self.b\n",
    "            if t > 1:\n",
    "                h[t] += self.W @ h[t-1] + self.b\n",
    "            h[t] = np.tanh(h[t])\n",
    "            o[t] = self.softmax( self.V.T @ h[t] + self.c)\n",
    "        return (o,h)\n",
    "\n",
    "\n",
    "\n",
    "    def backward(self, x, y, clip=None):\n",
    "        T = len(x)\n",
    "        o,h = self.forward(x)\n",
    "        dLdU = np.zeros(self.U.shape)\n",
    "        dLdV = np.zeros(self.V.shape)\n",
    "        dLdW = np.zeros(self.W.shape)\n",
    "        dLdb = np.zeros(self.b.shape)\n",
    "        dLdc = np.zeros(self.c.shape)\n",
    "        # dL/do\n",
    "        delta_o = o\n",
    "        # Notice, only evaluting at last output of network, yHat - y \n",
    "        delta_o[ np.arange(T), y ] -= float(y) \n",
    "        # dL/dh\n",
    "        delta_h = np.zeros((T, self.hdim))\n",
    "        for t in reversed(range(T)):\n",
    "\n",
    "            # collect errors on hidden states\n",
    "            delta_h[t] = self.V @ delta_o[T-1,:]\n",
    "            if t < T-1:\n",
    "                # collect errors on hidden states due to W\n",
    "                delta_h[t] = ( self.W @ np.diag(1-h[t+1]**2) ) @ delta_h[t+1]\n",
    "        for t in range(T):\n",
    "            # error on ouput bias\n",
    "            dLdc += delta_o[T-1,:]\n",
    "            # error on hidden bias \n",
    "            dLdb += (1-h[t]**2) * delta_h[t,:]\n",
    "            # error on hidden-output matrix\n",
    "            ot = delta_o[T-1,:][...,np.newaxis]\n",
    "            ht = h[t,:][...,np.newaxis]\n",
    "            dht = delta_h[t,:][...,np.newaxis]\n",
    "\n",
    "            dLdV += ht @ ot.T \n",
    "            # error on hidden-hidden W\n",
    "            if t > 0 :\n",
    "                h_t = h[t-1,:][...,np.newaxis]\n",
    "                dLdW += ( h_t @ dht.T )@np.diag(1-h[t]**2)\n",
    "            xt = x[t][...,np.newaxis]\n",
    "            dLdU += xt @ dht.T @ np.diag(1-h[t]**2)\n",
    "\n",
    "        if clip is not None:\n",
    "            dLdb = np.clip(dLdb, -clip, clip)\n",
    "            dLdc = np.clip(dLdc, -clip, clip)\n",
    "            dLdV = np.clip(dLdV, -clip, clip)\n",
    "            dLdW = np.clip(dLdW, -clip, clip)\n",
    "            dLdU = np.clip(dLdU, -clip, clip)\n",
    "        return (dLdU, dLdV, dLdW, dLdb, dLdc)\n",
    "\n",
    "\n",
    "    def step(self,x,y,lr=0.0001):\n",
    "        dLdU, dLdV, dLdW, dLdb, dLdc = self.backward(x,y)\n",
    "        self.U -= lr * dLdU\n",
    "        self.V -= lr * dLdV\n",
    "        self.W -= lr * dLdW \n",
    "        self.b -= lr * dLdb \n",
    "        self.c -= lr * dLdc \n",
    "    \n",
    "\n",
    "    def Loss(self, x,y):\n",
    "        o,h = self.forward(x)      \n",
    "        yHat= o[len(x)-1, :]\n",
    "        y_1h = [0.0]*len(yHat)\n",
    "        y_1h[int(y)] = 1.0\n",
    "        LOSS = self.categorical_cross_entropy_loss(yHat, y_1h)\n",
    "        return LOSS\n",
    "\n",
    "\n",
    "    def categorical_cross_entropy_loss(self, yHats, ys):\n",
    "        loss = 0.0\n",
    "        e =  1e-15 # adding to pred values for numerical stability\n",
    "        for pred,true in zip(yHats, ys):\n",
    "            loss += -1.0*(xlogy(true, pred+e) + xlog1py(1.0-true,-pred+e))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling synthetic time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYBUlEQVR4nO3debRdZXnH8e+PMGiVApLIkJAEFtEKWlQuk7QIAhaQEqVSw2BBi1EXIFZcNoJFpbaLarFQwWoWpCIigyiaQpBBBHRpIDeUKcHUmJpyA8hlFAeGmKd/nB09uTl3OPfsu6f391nrrpw93P2+52af57z72e/7bkUEZmbWfJuUXQEzMyuGA76ZWSIc8M3MEuGAb2aWCAd8M7NEOOCbmSXCAd9qT9INkk4sux5mVSf3w7eySfo58EfAzhHx62zdycAJEXFgiVUzaxS38K0qJgGnl10JsyZzwLeq+BzwUUlbd9oo6U2Slkh6Jvv3TW3bbsuuCJC0q6Tbs/0el3RVtv4iSecNOeZCSX83THm7S7pZ0pOSfiHpzGz9FpLOl/Rw9nO+pC2ybZMlXSfp6ez3fiBpo8+YpE9L+kL2ejNJv5b0uWz5pZKek/SKbPkbkh7N3s8dknbP1u+TrZ/Udtx3SLove72JpHmSfibpCUlXrz+mpcsB36qiH7gN+OjQDVmguh74d2Bb4PPA9ZK27XCcfwRuArYBpgFfyNZfChy7PgBLmgwcAny9Q3lbArcA3wV2BHYFvpdtPgvYF3g9sAewN/CJbNsZwAAwBdgOOBPolDO9HTgwe70X8ChwQLa8H7AiIp7Mlm8AZgGvBO4GLgeIiDuBXwNvaTvucW3v5zTg7cCbs/fwFHBRh7pYQhzwrUrOBk6TNGXI+rcBP42IyyJibURcAfwE+MsOx3gRmAHsGBHPRcQPASLiLuAZ4OBsvznAbRHxiw7HOBJ4NCLOy47xbBZgAY4HzomIxyJiEPg08O62sncAZkTEixHxg+h8k+zHwKzsC+sA4BJgqqSX0wrQt6/fMSIWZOU/D3wK2EPSVtnmK4Bj4fdfUkdk6wA+AJwVEQNtv/tOSZt2qI8lwgHfKiMiHgCuA+YN2bQjsHrIutXA1A6H+Rgg4C5JyyS9t23bpcAJ2esTgMuGqcpOwM+G2Ta0LquzddBKS60EbpK0StLQ9wFARPyW1hXNm2kF/NuBHwH70xbwJU2SdG6Wlvkl8PPsEJOzf78OHJ2llI4G7o6I9XWbAVybpZeeBh4EfkfrysMS5YBvVfNJ4H1sGMwfphXA2k0H1gz95Yh4NCLeFxE7Au8Hvihp12zz14DZkvYAXgN8e5g6PATsMsy2oXWZnq0ja4mfERG7AEcBH5F0cIdjQCuovwV4A7AkW/4LWimiO7J9jgNm00o9bQXMzNYrK285rS+cw9kwnbP+PRweEVu3/bwkIjb6m1k6HPCtUiJiJXAV8KG21YuAV0k6TtKmkt4F7EbramADko6RNC1bfIpWDn1dduwBWsH1MuCbWUu7k+uAHSR9OLtJu6WkfbJtVwCfkDQluw9wNq0vEiQdmd00Fq300e/Wl93B7cDfAMsj4gVa9y9OBv43SxUBbAk8DzxBq9vqP3c4ztdp9W46APhG2/ovAf8kaUZWtymSZg9TF0uEA75V0TnAy9YvRMQTtPLqZ9AKfh8DjoyIxzv87l7AnZJ+BSwETo+IVW3bLwVex/DpHCLiWeBQWvcIHgV+ChyUbf4MrXTMfcD9tG6kfibbNovWzd5f0crTfzEivj9MMT8CXsofWvPLgefalgG+SqsFvybbvrjDca6glQa6dcjf4wJa7/8mSc9mv7tPh9+3hHjglSVF0gG0WuQzhrmhatZYbuFbMiRtRiv9cbGDvaXIAd+SIOk1wNO0uk2eX2plzErilI6ZWSLcwjczS0SlR91Nnjw5Zs6cWXY1zMxqY+nSpY9HxNDR6kDFA/7MmTPp7+8vuxpmZrUhaeio9N9zSsfMLBEO+GZmiXDANzNLhAO+mVkiHPDNzBLhgG9mlggHfOto6eqnuOj7K1m6+qmyq2JmOal0P3wrx9LVT3H8xYt5Ye06Nt90Ey4/eV/2nLFN2dUysx65hW8bWbzqCV5Yu451AS+uXcfiVU+UXSUzy4EDvm1k3122ZfNNN2GSYLNNN2HfXbYtu0pmlgOndGwje87YhstP3pfFq55g3122dTrHrCEc8K2jPWds40Bv1jBO6ZiZJcIB38wsEQ74ZmaJcMA3M0uEA76ZWSJyCfiSFkh6TNIDw2w/UNIzku7Jfs7Oo1wzMxu7vLplfgW4EPjqCPv8ICKOzKk8MzPrUi4t/Ii4A3gyj2OZmdnEKDKHv5+keyXdIGn34XaSNFdSv6T+wcHBAqtnZtZsRQX8u4EZEbEH8AXg28PtGBHzI6IvIvqmTJlSUPXMzJqvkIAfEb+MiF9lrxcBm0maXETZZmbWUkjAl7S9JGWv987K9Zy7ZmYFyqWXjqQrgAOByZIGgE8CmwFExJeAdwIflLQW+C0wJyIij7LNzOpo6eqnCp+RNpeAHxHHjrL9QlrdNs3MklfWU+U80tbMrGBlPVXOAd/MuuaH3PemrKfK+QEoZtYVP+S+d2U9Vc4B38y60ikd4YDfvTKeKueUjpl1xQ+5ry+38M2sK37IfX054JtZ1/yQ+3pySsfMLBEO+LiLmZmlIfmUjruYmeWnjOkCbOySD/juYmaWDzeeqi/5lI67mJnlo6zpAmzskm/hu4uZWT7WN55eXLvOjaeKUpVnKe7r64v+/v6yq2FmY+QcfvkkLY2Ivk7bkm/hm1l+3D+/2pLP4ZuZpcIB38wsEQ74ZmaJcMA3M0uEA751xdNQmNVXLr10JC0AjgQei4jXdtgu4ALgCOA3wEkRcXceZVtxPJLSrN7yauF/BThshO2HA7Oyn7nAf+RUrhXIIynN6i2XgB8RdwBPjrDLbOCr0bIY2FrSDnmUbcXxNBRm9VbUwKupwENtywPZukeG7ihpLq2rAKZPn15I5WxsPA2FWb1VbqRtRMwH5kNraoWSq2NDeCSlWX0V1UtnDbBT2/K0bJ1ZLbh3kjVBUS38hcCpkq4E9gGeiYiN0jlmVeTeSdYUeXXLvAI4EJgsaQD4JLAZQER8CVhEq0vmSlrdMt+TR7lmRfBDcvLhmTTLl0vAj4hjR9kewCl5lGVWNM/z3jtfJVVD5W7amlWNeyf1zldJ1eCAbzYG7p3UG18lVYMDvplNOF8lVUNSAd83jczK46uk8iUT8H3TyMxSl8z0yJ74y8xSl0zA98RfZpa6ZFI6vmlkZqlLJuCDbxqZWdqSSemYmaWukQHfMxta2XwOWhU1LqXj7pfWizzGavgctKpqXMD3nB02XnkFap+DVlWNS+m4+6WNV15jNXwOWlU1roXv7pc2XnlN8OVz0KpKranqq6mvry/6+/vLroYlxPMtWd1JWhoRfZ22Na6Fb2Pn4LYxj9WwJnPAT5R7kuTDX5pWJw74I2jyh9k9SXrnL02rGwf8YTT9w+wnEPXOX5pWN7l0y5R0mKQVklZKmtdh+0mSBiXdk/2cnEe5E6np0ymv70nykbe+unFfZkVx90ubCBM5SrvnFr6kScBFwKHAALBE0sKIWD5k16si4tReyytKk1rAw6WmfIOyN+5+aXmb6MxCHimdvYGVEbEKQNKVwGxgaMCvlaZ8mJuemiqbvzQtTxOdJswjpTMVeKhteSBbN9RfSbpP0jWSdhruYJLmSuqX1D84OJhD9cZvzxnbcMpBu9b6A9301JRZk0x0mrCom7b/BVwREc9Lej9wKfCWTjtGxHxgPrQGXhVUv8ZqUmrKrOkmOrOQR8BfA7S32Kdl634vItqblRcDn82hXBuDpqSmzFIxkWnCPAL+EmCWpJ1pBfo5wHHtO0jaISIeyRaPAh7MoVwbI+eZzQxyCPgRsVbSqcCNwCRgQUQsk3QO0B8RC4EPSToKWAs8CZzUa7lmZtYdT55mZtYgI02e1rj58M3MqqRKj7v01AqWiybPO2Q2XlUbB+OAbz2r2kltVhVVm2/JKR3rmQd3mXVWtfmW3MK3nnlwlxWpTunDqo2DcS8dy0WdPoRWX04fjs6POLQJ58FdVoSq5cTrxjl8M6tU18GRVC0nXjdu4Zslrk5pkqrlxOvGAd+S4/sNG6pbmsTpw/FzwLek1Kk1WxT3skqHA74lpW6t2SI4TZIOB3xLiluznTlNkgYHfEuKW7OWMgd8S45bs5Yq98M3M0uEA76ZWSIc8M2sVHUZ5dsEzuGbFcwDv/7A4yKK5YBvjVXFwOoAtyGPiyhWLikdSYdJWiFppaR5HbZvIemqbPudkmbmUa7ZcNYH1vNuWsHxFy+uTLrAD4vZ0EiToTnVk7+eW/iSJgEXAYcCA8ASSQsjYnnbbn8LPBURu0qaA/wL8K5ey05VFVuuVVPVlqMHfm1ouHERvhKaGHmkdPYGVkbEKgBJVwKzgfaAPxv4VPb6GuBCSYoqP31lFGUFXX8QxqaqgdUDvzbWaVxEVb+w6y6PgD8VeKhteQDYZ7h9ImKtpGeAbYHHhx5M0lxgLsD06dNzqF7+ygy6/iCMTZUDqwd+ja6qX9h1V7mbthExH5gPrUccllydjsoMuv4gjJ0Da31V+Qu7zvII+GuAndqWp2XrOu0zIGlTYCugtnerygy6/iBYKvyFnb88Av4SYJaknWkF9jnAcUP2WQicCPwYeCdwa53z92UHXX8QzGw8eg74WU7+VOBGYBKwICKWSToH6I+IhcAlwGWSVgJP0vpSqDUHXTOrm1xy+BGxCFg0ZN3Zba+fA47Joywzs07cXXl0lbtpa2bWLXdXHhtPnmZmtecRzGPjgN8gHopuqRppigb7A6d0GsKXtJaysnvO1YUDfkOkMALXN+VsJO45NzoH/IZo+ghcX8GY9c4BvyGafkmbwhWM2URzwG+QJl/SNv0KxqwIDvhWC02/gjErggO+1UaTr2DMiuB++GZmiXDANzNLhAO+mVkiHPDNzBLhgG9mlggHfDOzRDjgm5klwgHfzCwRDvhmZolwwDczS0RPAV/SKyTdLOmn2b8dx71L+p2ke7Kfhb2Uac3nJ3dZHdXhvO11Lp15wPci4lxJ87Llv++w328j4vU9lmU11O1DSzzvvdVRXc7bXlM6s4FLs9eXAm/v8XjWIOs/BOfdtILjL148ppbPeB5GXYeWlTVbXR6i3mvA3y4iHslePwpsN8x+L5HUL2mxpLePdEBJc7N9+wcHB3usnpVpPB+Cbh9GPZ4vlabzF2Dx6vIQ9VFTOpJuAbbvsOms9oWICEkxzGFmRMQaSbsAt0q6PyJ+1mnHiJgPzAfo6+sb7nhWA+N5aEm38977SVgbqktqoWnq8ryGUQN+RBwy3DZJv5C0Q0Q8ImkH4LFhjrEm+3eVpNuANwAdA741x3g/BN3Me+8nYW3IX4DlqcPzGnq9absQOBE4N/v3O0N3yHru/CYinpc0Gdgf+GyP5VpNTPSHoC4tq6L4C9BGoojxZ00kbQtcDUwHVgN/HRFPSuoDPhARJ0t6E/BlYB2tewbnR8QlYzl+X19f9Pf3j7t+ddBtLxaz0ficSpukpRHR13FbLwF/ojU94DvfamZ5Gynge6RtierSlcssNU3t6eSHmJfI+Vaz6mnylbcDfol8w9Gseprc08kBv2R16MpllpImX3k74BfEPSfM6qHJV94O+AVock7QrImaeuXtXjoFcG8cM6sCB/wC1GViJTNrNqd0CtDknKCZ1YcDfkGamhM0s/pwSsfMLBEO+GZmiXDAN6uIps7fYtXhHL5ZBXishhXBLXyzCvBYDSuCA75ZBXishhXBKR2zCvBYDSuCA75ZRXisRvXVfRJEB3wzszFowo115/DNzMagCTfWewr4ko6RtEzSOkkdH5qb7XeYpBWSVkqa10uZZmZlaMKN9V5TOg8ARwNfHm4HSZOAi4BDgQFgiaSFEbG8x7LNzArThBvrPQX8iHgQQNJIu+0NrIyIVdm+VwKzAQd8MytEXjdb635jvYibtlOBh9qWB4B9httZ0lxgLsD06dMntmZm1nhNuNmal1Fz+JJukfRAh5/ZE1GhiJgfEX0R0TdlypSJKMLMEtKEm615GbWFHxGH9FjGGmCntuVp2bpGqns/Xasen1O9WX+z9cW162p7szUvRaR0lgCzJO1MK9DPAY4roNzC+dLR8uZzqndNuNmal167Zb5D0gCwH3C9pBuz9TtKWgQQEWuBU4EbgQeBqyNiWW/VriZfOlrefE7lY88Z23DKQbsmHeyh91461wLXdlj/MHBE2/IiYFEvZdWBLx0tbz6nLE+KiLLrMKy+vr7o7+8vuxpdcb7V8uZzyrohaWlEdBwI67l0clb3frpWPT6nLC+eS8fMLBEO+GZmiXDAN0uIH5SeNufwK8o36ixv7tNvDvgV5A+mTYROffp9XqXFKZ0K8mAbmwhNmM/deuMWfgV5sI1NBE8xYB54VVHO4ZvZeHjgVQ15sI2Z5c05fDOzRDjgm5klwgHfSuEBQL3z39C65Ry+Fc7jDHrnv6GNh1v4VjiPM+id/4Y2Hg74VjgPAOqd/4Y2Hu6Hb6XwOIPe+W9onbgfvlWOxxn0zn9D65ZTOmZmiegp4Es6RtIySeskdbyEyPb7uaT7Jd0jyTkas5pw189m6TWl8wBwNPDlMex7UEQ83mN5ZlYQd/1snp5a+BHxYESsyKsyZlYd7vrZPEXl8AO4SdJSSXNH2lHSXEn9kvoHBwcLqp6ZDeWun80zakpH0i3A9h02nRUR3xljOX8WEWskvRK4WdJPIuKOTjtGxHxgPrS6ZY7x+GaWM8+f3zyjBvyIOKTXQiJiTfbvY5KuBfYGOgZ8M6sOd/1slglP6Uh6maQt178G3krrZq+ZmRWo126Z75A0AOwHXC/pxmz9jpIWZbttB/xQ0r3AXcD1EfHdXso1M7Pu9dQtMyKuBa7tsP5h4Ijs9Spgj17KMTOz3nmkrZlZIhzwzcwS4YBvZpYIB3wzs0Q44JtZslKbHM7z4ZtZklKcHM4tfDNLUoqTwzngm1mSUpwczikdM0tSipPDOeCbWbJSmxzOKR0zs0Q44JuZJcIB38wsEQ74ZmaJcMA3M0uEA76ZWSIUUd3nhEsaBFZPwKEnA49PwHGLUvf6Q/3fg+tfvrq/h4mq/4yImNJpQ6UD/kSR1B8RfWXXY7zqXn+o/3tw/ctX9/dQRv2d0jEzS4QDvplZIlIN+PPLrkCP6l5/qP97cP3LV/f3UHj9k8zhm5mlKNUWvplZchzwzcwSkWzAl3SapJ9IWibps2XXZ7wknSEpJE0uuy7dkPS57O9/n6RrJW1ddp3GQtJhklZIWilpXtn16ZaknSR9X9Ly7Nw/vew6jYekSZL+W9J1ZddlPCRtLema7DPwoKT9iig3yYAv6SBgNrBHROwO/GvJVRoXSTsBbwX+r+y6jMPNwGsj4k+B/wE+XnJ9RiVpEnARcDiwG3CspN3KrVXX1gJnRMRuwL7AKTV8DwCnAw+WXYkeXAB8NyL+BNiDgt5LkgEf+CBwbkQ8DxARj5Vcn/H6N+BjQO3uvEfETRGxNltcDEwrsz5jtDewMiJWRcQLwJW0Gg61ERGPRMTd2etnaQWaqeXWqjuSpgFvAy4uuy7jIWkr4ADgEoCIeCEini6i7FQD/quAP5d0p6TbJe1VdoW6JWk2sCYi7i27Ljl4L3BD2ZUYg6nAQ23LA9QsWLaTNBN4A3BnyVXp1vm0GjrrSq7HeO0MDAL/maWlLpb0siIKbuwjDiXdAmzfYdNZtN73K2hd0u4FXC1pl6hYH9VR3sOZtNI5lTVS/SPiO9k+Z9FKM1xeZN1SJ+nlwDeBD0fEL8uuz1hJOhJ4LCKWSjqw5OqM16bAG4HTIuJOSRcA84B/KKLgRoqIQ4bbJumDwLeyAH+XpHW0JjIaLKp+YzHce5D0OlqthHslQSsdcrekvSPi0QKrOKKR/g8AJJ0EHAkcXLUv22GsAXZqW56WrasVSZvRCvaXR8S3yq5Pl/YHjpJ0BPAS4I8lfS0iTii5Xt0YAAYiYv2V1TW0Av6ESzWl823gIABJrwI2p0az7kXE/RHxyoiYGREzaZ1Ab6xSsB+NpMNoXZYfFRG/Kbs+Y7QEmCVpZ0mbA3OAhSXXqStqtRAuAR6MiM+XXZ9uRcTHI2Jadt7PAW6tWbAn+5w+JOnV2aqDgeVFlN3YFv4oFgALJD0AvACcWJMWZpNcCGwB3JxdpSyOiA+UW6WRRcRaSacCNwKTgAURsazkanVrf+DdwP2S7snWnRkRi8qrUpJOAy7PGg6rgPcUUainVjAzS0SqKR0zs+Q44JuZJcIB38wsEQ74ZmaJcMA3M0uEA76ZWSIc8M3MEvH/2KTLR7k+QIsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.linspace(-2*np.pi, 2*np.pi, 50)\n",
    "\n",
    "\n",
    "def noisy_sin_wave(x):\n",
    "    return np.sin(x*0.6) + np.random.normal(loc=0, scale=0.1)\n",
    "\n",
    "\n",
    "def noisy_cos_wave(x):\n",
    "    return np.cos(x*2) + np.random.normal(loc=0, scale=0.5)\n",
    "\n",
    "\n",
    "def noisy_tan_wave(x):\n",
    "    return np.tan(x) + np.random.normal(loc=0, scale=0.3)\n",
    "\n",
    "\n",
    "def plot_noisy_func(func, domain,title):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.set_title(title)\n",
    "    ax.plot(domain,np.vectorize(func)(domain), \".\")\n",
    "\n",
    "\n",
    "def create_sample_seq(func1, domain, label):\n",
    "    X = np.array([np.vectorize(func1)(domain)])\n",
    "    Y = np.array([label]*X.shape[0])\n",
    "    X = X.T\n",
    "    return X,Y\n",
    "\n",
    "plot_noisy_func(noisy_sin_wave, X, \"Noisy sin wave\")\n",
    "plot_noisy_func(noisy_cos_wave, X, \"Noisy cos wave\")\n",
    "plot_noisy_func(noisy_tan_wave, X, \"Noisy tan wave\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synthetic data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_sin, var_cos, var_tan = sy.symbols(\"sin+e, cos+e, tan+e\")\n",
    "sy.Matrix([var_sin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy.Matrix([var_cos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy.Matrix([var_tan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(domain, sample_size=30):\n",
    "    X0 = [ create_sample_seq(noisy_sin_wave, domain, 0) for _ in range(sample_size)]\n",
    "    X1 = [ create_sample_seq(noisy_cos_wave, domain, 1) for _ in range(sample_size)]\n",
    "    X2 = [ create_sample_seq(noisy_tan_wave, domain, 2) for _ in range(sample_size)]\n",
    "    X = [*X0, *X1 , *X2]\n",
    "    random.shuffle(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2900107e17e34fad99d97724348345fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.006789289301429512\n",
      "Epoch 1 Loss 5.001694040009544e-05\n",
      "Epoch 2 Loss 0.0023826277493174796\n",
      "Epoch 3 Loss 2.4457006554135937e-05\n",
      "Epoch 4 Loss 3.065480698920417e-07\n",
      "Epoch 5 Loss 2.2767088382015394e-07\n",
      "Epoch 6 Loss 1.6945798382666805e-07\n",
      "Epoch 7 Loss 1.4796068560696907e-07\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "MAX_EPOCHS = 10\n",
    "LR=0.001\n",
    "\n",
    "model = RNN(input_dim=1, output_dim=3, hidden_dim=128)\n",
    "domain = np.linspace(-2*np.pi, 2*np.pi, 50)\n",
    "X = data_loader(domain)\n",
    "\n",
    "for epoch in tqdm(range(MAX_EPOCHS)):\n",
    "    loss = 0\n",
    "    for pair in X:\n",
    "        x,y  = pair        \n",
    "        loss += model.Loss(x, y)\n",
    "        model.step(x, y, lr=LR)\n",
    "        loss = loss / len(x)\n",
    "    print(f\"Epoch {epoch} Loss {loss}\")\n",
    "    loss_history.append(loss)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "ground-up-Awl4p5GG",
   "language": "python",
   "name": "ground-up-awl4p5gg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
