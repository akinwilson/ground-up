{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import warnings\n",
    "import sympy as sy\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.special import xlogy, xlog1py \n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "InteractiveShell.ast_node_interactive = \"all\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a system where:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h^t= f (h^{t-1},\\theta)  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta \\text{: parameters shared across all time steps}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, its state at time step t, is dependent only on a set a parameters and the previous state at t-1\n",
    "<br>\n",
    "<br>\n",
    "Let the state of the system, h, also be depedent on an input at the respective time step, x:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h^t= f (h^{t-1},x^{t},\\theta)  \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state h now contains information about the entire past history of inputs, x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider now a system that given the hidden state, h,produces an output o, for each time step. This output is passed to an activation function made to predict the target, y, at the respective time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "o^t= g (h^{t},\\theta')  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta' \\text{: a different set of parameters as $\\theta$}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define now define $\\theta$ and $\\theta'$ as the weight matrices describing the relation between the input-to-hidden, hidden-to-hidden and hidden-to-output notes; $U$, $W$ and $V$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "z^t=  W^{T}h^{t-1} + U^{T}x^t +b \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "h^{t} = \\phi(z^t)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "o^t = V^Th^{t} + c\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $b$ and $c$ are biases, $\\phi$ is an activation function. <br><br>\n",
    "**Note**: matrices $U$, $W$ and $V$ are not indexed by time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider the following schematic to get a better understanding for a reccurent system\n",
    "<img src=\"media/RNNFoldedandUnfolded.png\" style=\"height: 300px;\"/>\n",
    "credits: fdeloche "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each time step, we have a sequential total loss up to time step $\\tau$, $L^\\tau$, defined as the difference between our prediction and the target, at each output, upto the time step $\\tau$\n",
    "<br>\n",
    "<br>\n",
    "Consider the task of multi-class classification. \n",
    "<br>\n",
    "<br>\n",
    "Consequently, the output activation function is the normalized expontential function, a.k.a the _softmax function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L = \\sum_{t=1}^{\\tau} l\\big(o^{t}\\big)\n",
    "\\text{: Total loss upto time step $\\tau$}  \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}^t_i = \\frac{\\exp(o_i^t)}{\\sum_{j}\\exp(o_j^t)}\n",
    "\\text{: Softmax activation function for multi-class classification}\n",
    "\\end{equation}\n",
    "\n",
    "**NOTE** the softmax is a vector function, later when taking the derivative, in reality I am finding the Jacobian of it in its vector form, but here I denote one element of it, the $i^{th}$\n",
    "\n",
    "\\begin{equation}\n",
    "l = - \\sum_{m=0}^{M-1}y_{m}^{t} \\log\\Big(\\hat{y}_{m}^{t}\\Big)\n",
    "\\text{: M categorical cross entropy for predictions at time step $t$}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization process differs from standard back-propagation (like descirbed for a vanilla feedforward network). Usng the above assumptions, I will go through the derivation analogous optimization process for recurrent networks;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back propagation through time\n",
    "\n",
    "Per example loss w.r.t to the output element $o_i$ at time $t$; $o_i^{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{o_{i}^{t}} L = \\frac{\\partial{L}}{\\partial{l(o_i^t)}} \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}}\n",
    "\\end{equation}\n",
    "Note that:\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{L}}{\\partial{l(o_i^t)}} = 1\n",
    "\\end{equation}\n",
    "and that:\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}}\n",
    "\\end{equation}\n",
    "is the derivative of the categorical cross-entropy\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} \\frac{y_j^{t}}{\\hat{y}_j^{t}}\\frac{\\partial{\\hat{y}^{t}_j}}{\\partial{o_i^{t}}} } - [1]\n",
    "\\end{equation}\n",
    "The softmax functions is:\n",
    " \\begin{equation}\n",
    " \\hat{y}^t_i = \\frac{\\exp(o_i^t)}{\\sum_{j}\\exp(o_j^t)}\n",
    "\\end{equation}\n",
    "Taking its derivative gives:\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "    \\frac{\\partial{\\hat{y}^{t}_i}}{\\partial{o_j^{t}}} = \\hat{y}^{t}_{i} \\Big( \\delta_{ij}  -  \\hat{y}^{t}_{j} \\Big)\n",
    "}- [2]\n",
    "\\end{equation}\n",
    "_look at the different cases to see why this is true_ i.e. $i=j$ and $i \\neq j$\n",
    "<br><br>\n",
    "Lets sub [2] into [1], and splitting into the cases where $i=j$ and $i \\neq j $:\n",
    "\n",
    " \\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} \\frac{y_j^{t}}{\\hat{y}_j^{t}} \\hat{y}^{t}_{j} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation}\n",
    "\n",
    " \\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} y_j^{t} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation}\n",
    " \n",
    "Lets now split the sum up for the two cases;\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} \\Bigr|_{j=i} + \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} \\Bigr|_{j \\neq i}  =  -y^{t}_{i}(\\delta_{ii} - \\hat{y}_{i})^{t} - \\sum_{j \\neq i} y_j^{t} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation} \n",
    "Simplfying down: \n",
    "\n",
    "\\begin{equation}\n",
    " \n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  -y^{t}_{i}(1 - \\hat{y}_{i})^{t} - \\sum_{j \\neq i} y_j^{t} \\Big( 0 -\\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation} \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} y_j^{t} \\hat{y}^{t}_{i}  -y^{t}_{i}(1 - \\hat{y}_{i})^{t} \n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} y_j^{t} \\hat{y}^{t}_{i}+y^{t}_{i}\\hat{y}_{i}^{t}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "Recall that $\\sum_{j} y_j = 1$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} \\Big( y_j^{t} +y^{t}_{i} \\Big) \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j} \\Big( y_j^{t} \\Big) \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "}\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets calculate the gradient on the internel nodes $h^t$ from the end of the sequence $\\tau$.\n",
    "<br>\n",
    "I am going to use vector notation here on out. I.e. $h_i^{t}$ becomes $h^t$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^\\tau} L = \\Bigg( \\frac{ \\partial{o^{\\tau}}}\n",
    "{\\partial{h^{\\tau}}} \\Bigg)^{T} \\nabla_{o^\\tau} L\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{h^\\tau} L = V \\nabla_{o^\\tau} L\n",
    "\\end{equation}\n",
    "we iterate backwards through time. Note the dependency of $h^t$ on both $o^t$ and $h^{t+1}$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = \\Bigg( \\frac{ \\partial{h^{t+1}}}\n",
    "{\\partial{h^{t}}} \\Bigg)^{T} \\nabla_{h^{t+1}} L +\n",
    "\\Bigg( \\frac{ \\partial{o^{t}}}\n",
    "{\\partial{h^{t}}} \\Bigg)^{T} \\nabla_{o^{t}} L \n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivate of the hidden units  w.r.t their previous time step is:\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{ \\partial{h^{t+1}} }\n",
    "{\\partial{h^{t}} }  =  \\frac{ \\partial{h^{t+1}} }{ \\partial{z^{t+1} } }\n",
    "\\frac{ \\partial{z^{t+1} } } { \\partial{h^{t}} }\n",
    "\\end{equation}\n",
    "This leads to:\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{ \\partial{h^{t+1}} }\n",
    "{\\partial{h^{t}} }  =  diag\\Bigg( \\phi'\\big(z^{t+1}\\big) \\Bigg) W^T\n",
    "\\end{equation}\n",
    "**Note** diag: considering only the leading diagonal values and setting all others to 0. \n",
    "<br><br>\n",
    "For RNNs , we want to use a saturating activation to avoid gradient explosions <br><br>\n",
    "e.g. hyperbolic tagent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = W  diag \\Big( \\phi'\\big(z^{t+1}\\big) \\Big)   \\nabla_{h^{t+1}} L +\n",
    "V \\nabla_{o^{t}} L \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets specify the activation function (using the hyperpolic tagent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = W  diag \\Big( \n",
    "     1 - \\big(h^{t+1}\\big)^2\n",
    "    \\Big)  \\nabla_{h^{t+1}} L +\n",
    "V \\nabla_{o^{t}} L \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the gradients on the biases $b$ and $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{c} L  = \\sum_{t} \\Bigg(\n",
    "     \\frac{\\partial{o^t}}{\\partial{c^t}} \n",
    "     \\Bigg)^{T} \\nabla_{o^t} L\n",
    "\\end{equation}\n",
    "since $\\frac{\\partial{o^t}}{\\partial{c^t}} = 1$\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{c} L  = \\sum_{t} \\nabla_{o^t} L\n",
    "\\end{equation}\n",
    "Next:\n",
    "\\begin{equation}\n",
    "\\nabla_{b} L  = \\sum_{t}  \\Bigg(\n",
    "     \\frac{\\partial{h^t}}{\\partial{b^t}} \n",
    "     \\Bigg)^{T}  \\nabla_{h^t} L\n",
    "\\end{equation}\n",
    "Since $b$ is dependent on h through the activation function $\\phi$, we have: \n",
    "\n",
    "Next:\n",
    "\\begin{equation}\n",
    "\\nabla_{b} L  = \\sum_{t}  diag \\Bigg( \\phi' \\Big( z^t \\Big) \\Bigg) \\nabla_{h^t} L\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative w.r.t to $V$; the hidden-ouput matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{V} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial o_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{V} O_i^{t}\n",
    "\\end{equation}\n",
    "Leading to:\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{V} L  = \\sum_{t} h^t \\Big(\\nabla_{o^t} L \\Big)^T\n",
    "}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the derivative w.r.t the weight matrices $W$ and $U$, we introduce dummy variables $W^t$ and $U^t$. These are copies of each other at each time step, summing these up will give us the total gradient. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{W} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial h_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{W^t} h_i^{t}\n",
    "\\end{equation}\n",
    "giving: \n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{W} L  = \\sum_{t} h^{t-1} \\Big(\\nabla_{h^t} L \\Big)^T  diag \\Bigg( \\phi ' \\big(z^t \\big) \\Bigg)\n",
    "\n",
    "}\n",
    "\\end{equation}\n",
    "for the derivative of w.r.t $U$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{U} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial h_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{U^t} h_i^{t}\n",
    "\\end{equation}\n",
    "giving: \n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{U} L  = \\sum_{t} x^{t} \\Big( \\nabla_{h^t} L \\Big)^T \n",
    "     diag \\Bigg( \\phi ' \\big(z^t \\big) \\Bigg)\n",
    "\n",
    "}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network implementation with backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, idx2wave):\n",
    "        # network variables \n",
    "        self.idim = input_dim\n",
    "        self.hdim = hidden_dim\n",
    "        self.odim = output_dim\n",
    "        # initialise weights \n",
    "        self.U = np.random.uniform(- np.sqrt(1./self.idim),\n",
    "                                     np.sqrt(1./self.idim),\n",
    "                                    (self.idim, self.hdim) )\n",
    "\n",
    "        self.V = np.random.uniform( -np.sqrt(1./self.hdim),\n",
    "                                     np.sqrt(1./self.hdim), \n",
    "                                    (self.hdim,self.odim))\n",
    "\n",
    "        self.W = np.random.uniform( -np.sqrt(1./self.hdim),\n",
    "                                     np.sqrt(1./self.hdim), \n",
    "                                    (self.hdim,self.hdim))\n",
    "        # bias init \n",
    "        self.b = np.zeros(self.hdim)\n",
    "        self.c = np.zeros(self.odim)\n",
    "\n",
    "        self.idx2wave = idx2wave \n",
    "\n",
    "    def softmax(self,x):\n",
    "        '''\n",
    "        Note that this is a numerically stable version of softmax.\n",
    "        We substract the max value from all elements.\n",
    "        Overflow of a single element, or underflow of all elements,  will render the output usless.\n",
    "        subtracting max leaves only non-positive values ---> no overflow \n",
    "        at least one element = 0 ---> no vanishing denominator (underflow is some enteries is okay) \n",
    "         '''\n",
    "        xt = np.exp(x-np.max(x))\n",
    "        return xt / np.sum(xt)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Single example pass forward, all the way through the network\n",
    "        T = len(x)\n",
    "        # will stack as rows\n",
    "        h = np.zeros((T,self.hdim))\n",
    "        o = np.zeros((T,self.odim))\n",
    "        for t in range(T):\n",
    "            h[t] = self.U.T @ x[t] + self.b\n",
    "            if t > 1:\n",
    "                h[t] += self.W @ h[t-1] + self.b\n",
    "            h[t] = np.tanh(h[t])\n",
    "            o[t] = self.softmax( self.V.T @ h[t] + self.c)\n",
    "        return (o,h)\n",
    "\n",
    "\n",
    "\n",
    "    def backward(self, x, y, clip=None):\n",
    "        T = len(x)\n",
    "        o,h = self.forward(x)\n",
    "        dLdU = np.zeros(self.U.shape)\n",
    "        dLdV = np.zeros(self.V.shape)\n",
    "        dLdW = np.zeros(self.W.shape)\n",
    "        dLdb = np.zeros(self.b.shape)\n",
    "        dLdc = np.zeros(self.c.shape)\n",
    "        # dL/do\n",
    "        delta_o = o\n",
    "        # Notice, only evaluting at last output of network, yHat - y \n",
    "        delta_o[ np.arange(T), y ] -= float(y) \n",
    "        # dL/dh\n",
    "        delta_h = np.zeros((T, self.hdim))\n",
    "        for t in reversed(range(T)):\n",
    "\n",
    "            # collect errors on hidden states\n",
    "            delta_h[t] = self.V @ delta_o[T-1,:]\n",
    "            if t < T-1:\n",
    "                # collect errors on hidden states due to W\n",
    "                delta_h[t] = ( self.W @ np.diag(1-h[t+1]**2) ) @ delta_h[t+1]\n",
    "        for t in range(T):\n",
    "            # error on ouput bias\n",
    "            dLdc += delta_o[T-1,:]\n",
    "            # error on hidden bias \n",
    "            dLdb += (1-h[t]**2) * delta_h[t,:]\n",
    "            # error on hidden-output matrix\n",
    "            ot = delta_o[T-1,:][...,np.newaxis]\n",
    "            ht = h[t,:][...,np.newaxis]\n",
    "            dht = delta_h[t,:][...,np.newaxis]\n",
    "\n",
    "            dLdV += ht @ ot.T \n",
    "            # error on hidden-hidden W\n",
    "            if t > 0 :\n",
    "                h_t = h[t-1,:][...,np.newaxis]\n",
    "                dLdW += ( h_t @ dht.T )@np.diag(1-h[t]**2)\n",
    "            xt = x[t][...,np.newaxis]\n",
    "            dLdU += xt @ dht.T @ np.diag(1-h[t]**2)\n",
    "\n",
    "        if clip is not None:\n",
    "            dLdb = np.clip(dLdb, -clip, clip)\n",
    "            dLdc = np.clip(dLdc, -clip, clip)\n",
    "            dLdV = np.clip(dLdV, -clip, clip)\n",
    "            dLdW = np.clip(dLdW, -clip, clip)\n",
    "            dLdU = np.clip(dLdU, -clip, clip)\n",
    "        return (dLdU, dLdV, dLdW, dLdb, dLdc)\n",
    "\n",
    "\n",
    "    def step(self,x,y,lr=0.0001):\n",
    "        dLdU, dLdV, dLdW, dLdb, dLdc = self.backward(x,y)\n",
    "        self.U -= lr * dLdU\n",
    "        self.V -= lr * dLdV\n",
    "        self.W -= lr * dLdW \n",
    "        self.b -= lr * dLdb \n",
    "        self.c -= lr * dLdc \n",
    "    \n",
    "\n",
    "    def Loss(self, x,y):\n",
    "        o,h = self.forward(x)      \n",
    "        yHat= o[len(x)-1, :]\n",
    "        y_1h = [0.0]*len(yHat)\n",
    "        y_1h[int(y)] = 1.0\n",
    "        LOSS = self.categorical_cross_entropy_loss(yHat, y_1h)\n",
    "        return LOSS\n",
    "\n",
    "\n",
    "    def categorical_cross_entropy_loss(self, yHats, ys):\n",
    "        loss = 0.0\n",
    "        e =  1e-15 # adding to pred values for numerical stability\n",
    "        for pred,true in zip(yHats, ys):\n",
    "            loss += -1.0*(xlogy(true, pred+e) + xlog1py(1.0-true,-pred+e))\n",
    "        return loss\n",
    "\n",
    "    def predict(self,x):\n",
    "        o,_ = self.forward(x)\n",
    "        output = list(o[len(x)-1, :]) \n",
    "        return output.index(max(output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling synthetic time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.linspace(-2*np.pi, 2*np.pi, 50)\n",
    "\n",
    "\n",
    "def noisy_sin_wave(x):\n",
    "    return np.sin(x*0.6) + np.random.normal(loc=0, scale=0.1)\n",
    "\n",
    "\n",
    "def noisy_cos_wave(x):\n",
    "    return np.cos(x*2) + np.random.normal(loc=0, scale=0.2)\n",
    "\n",
    "\n",
    "def noisy_tan_wave(x):\n",
    "    return np.tan(x) + np.random.normal(loc=0, scale=0.3)\n",
    "\n",
    "\n",
    "def plot_noisy_func(func, domain,title):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.set_title(title)\n",
    "    ax.plot(domain,np.vectorize(func)(domain), \".\")\n",
    "\n",
    "\n",
    "def create_sample_seq(func1, domain, label):\n",
    "    X = np.array([np.vectorize(func1)(domain)])\n",
    "    Y = np.array([label]*X.shape[0])\n",
    "    X = X.T\n",
    "    return X,Y\n",
    "\n",
    "plot_noisy_func(noisy_sin_wave, X, \"Noisy sin wave\")\n",
    "plot_noisy_func(noisy_cos_wave, X, \"Noisy cos wave\")\n",
    "plot_noisy_func(noisy_tan_wave, X, \"Noisy tan wave\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synthetic data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(domain, sample_size=30):\n",
    "    X0 = [ create_sample_seq(noisy_sin_wave, domain, 0) for _ in range(sample_size)]\n",
    "    X1 = [ create_sample_seq(noisy_cos_wave, domain, 1) for _ in range(sample_size)]\n",
    "    X2 = [ create_sample_seq(noisy_tan_wave, domain, 2) for _ in range(sample_size)]\n",
    "    X = [*X0, *X1 , *X2]\n",
    "    random.shuffle(X)\n",
    "    idx2wave = {0:\"sin\", 1:\"cos\", 2:\"tan\"}\n",
    "    return X, idx2wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41142848b39d40d6bd09cf4a70d71716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.024387287367504184\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "MAX_EPOCHS = 10\n",
    "LR=0.001\n",
    "domain = np.linspace(-2*np.pi, 2*np.pi, 50)\n",
    "X, idx2wave = data_loader(domain)\n",
    "\n",
    "model = RNN(input_dim=1, output_dim=3, hidden_dim=128, idx2wave=idx2wave)\n",
    "for epoch in tqdm(range(MAX_EPOCHS)):\n",
    "    loss = 0\n",
    "    for pair in X:\n",
    "        x,y  = pair        \n",
    "        loss += model.Loss(x, y)\n",
    "        model.step(x, y, lr=LR)\n",
    "        loss = loss / len(x)\n",
    "    print(f\"Epoch {epoch} Loss {loss}\")\n",
    "    loss_history.append(loss)\n",
    "    if loss < 1e-4:\n",
    "        print(\"*\"*20)\n",
    "        print(f\"Termination condition met at epoch: {epoch}.\")\n",
    "        print(\"*\"*20)\n",
    "        break \n",
    "\n",
    "\n",
    "\n",
    "X, idx2wave = data_loader(domain, sample_size=20)\n",
    "true, pred = [], []\n",
    "for idx in range(len(X)):\n",
    "    x, y = X[idx][0],X[idx][1]\n",
    "    out = model.predict(x)\n",
    "    true.append(list(y)[0])\n",
    "    pred.append(out)\n",
    "\n",
    "target_names = list(idx2wave.values())\n",
    "print( classification_report(true,pred, target_names=target_names)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "ground-up-Awl4p5GG",
   "language": "python",
   "name": "ground-up-awl4p5gg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
