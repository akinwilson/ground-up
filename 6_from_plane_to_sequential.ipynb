{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import warnings\n",
    "import sympy as sy\n",
    "from scipy.special import xlogy, xlog1py \n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "InteractiveShell.ast_node_interactive = \"all\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a system where:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h^t= f (h^{t-1},\\theta)  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta \\text{: parameters shared across all time steps}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, its state at time step t, is dependent only on a set a parameters and the previous state at t-1\n",
    "<br>\n",
    "<br>\n",
    "Let the state of the system, h, also be depedent on an input at the respective time step, x:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "h^t= f (h^{t-1},x^{t},\\theta)  \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state h now contains information about the entire past history of inputs, x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider now a system that given the hidden state, h,produces an output o, for each time step. This output is passed to an activation function made to predict the target, y, at the respective time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "o^t= g (h^{t},\\theta')  \n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\theta' \\text{: a different set of parameters as $\\theta$}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define now define $\\theta$ and $\\theta'$ as the weight matrices describing the relation between the input-to-hidden, hidden-to-hidden and hidden-to-output notes; $U$, $W$ and $V$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "z^t=  W^{T}h^{t-1} + U^{T}x^t +b \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "h^{t} = \\phi(z^t)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "o^t = V^Th^{t} + c\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $b$ and $c$ are biases, $\\phi$ is an activation function. <br><br>\n",
    "**Note**: matrices $U$, $W$ and $V$ are not indexed by time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider the following schematic to get a better understanding for a reccurent system\n",
    "<img src=\"media/RNNFoldedandUnfolded.png\" style=\"height: 300px;\"/>\n",
    "credits: fdeloche "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each time step, we have a sequential total loss up to time step $\\tau$, $L^\\tau$, defined as the difference between our prediction and the target, at each output, upto the time step $\\tau$\n",
    "<br>\n",
    "<br>\n",
    "Consider the task of multi-class classification. \n",
    "<br>\n",
    "<br>\n",
    "Consequently, the output activation function is the normalized expontential function, a.k.a the _softmax function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "L = \\sum_{t=1}^{\\tau} l\\big(o^{t}\\big)\n",
    "\\text{: Total loss upto time step $\\tau$}  \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y}^t_i = \\frac{\\exp(o_i^t)}{\\sum_{j}\\exp(o_j^t)}\n",
    "\\text{: Softmax activation function for multi-class classification}\n",
    "\\end{equation}\n",
    "\n",
    "**NOTE** the softmax is a vector function, later when taking the derivative, in reality I am finding the Jacobian of it in its vector form, but here I denote one element of it, the $i^{th}$\n",
    "\n",
    "\\begin{equation}\n",
    "l = - \\sum_{m=0}^{M-1}y_{m}^{t} \\log\\Big(\\hat{y}_{m}^{t}\\Big)\n",
    "\\text{: M categorical cross entropy for predictions at time step $t$}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization process differs from standard back-propagation (like descirbed for a vanilla feedforward network). Usng the above assumptions, I will go through the derivation analogous optimization process for recurrent networks;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back propagation through time\n",
    "\n",
    "Per example loss w.r.t to the output element $o_i$ at time $t$; $o_i^{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{o_{i}^{t}} L = \\frac{\\partial{L}}{\\partial{l(o_i^t)}} \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}}\n",
    "\\end{equation}\n",
    "Note that:\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{L}}{\\partial{l(o_i^t)}} = 1\n",
    "\\end{equation}\n",
    "and that:\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}}\n",
    "\\end{equation}\n",
    "is the derivative of the categorical cross-entropy\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} \\frac{y_j^{t}}{\\hat{y}_j^{t}}\\frac{\\partial{\\hat{y}^{t}_j}}{\\partial{o_i^{t}}} } - [1]\n",
    "\\end{equation}\n",
    "The softmax functions is:\n",
    " \\begin{equation}\n",
    " \\hat{y}^t_i = \\frac{\\exp(o_i^t)}{\\sum_{j}\\exp(o_j^t)}\n",
    "\\end{equation}\n",
    "Taking its derivative gives:\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "    \\frac{\\partial{\\hat{y}^{t}_i}}{\\partial{o_j^{t}}} = \\hat{y}^{t}_{i} \\Big( \\delta_{ij}  -  \\hat{y}^{t}_{j} \\Big)\n",
    "}- [2]\n",
    "\\end{equation}\n",
    "_look at the different cases to see why this is true_ i.e. $i=j$ and $i \\neq j$\n",
    "<br><br>\n",
    "Lets sub [2] into [1], and splitting into the cases where $i=j$ and $i \\neq j $:\n",
    "\n",
    " \\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} \\frac{y_j^{t}}{\\hat{y}_j^{t}} \\hat{y}^{t}_{j} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation}\n",
    "\n",
    " \\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = - \\sum_{j} y_j^{t} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation}\n",
    " \n",
    "Lets now split the sum up for the two cases;\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} \\Bigr|_{j=i} + \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} \\Bigr|_{j \\neq i}  =  -y^{t}_{i}(\\delta_{ii} - \\hat{y}_{i})^{t} - \\sum_{j \\neq i} y_j^{t} \\Big(\\delta_{ij}  -  \\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation} \n",
    "Simplfying down: \n",
    "\n",
    "\\begin{equation}\n",
    " \n",
    " \\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  -y^{t}_{i}(1 - \\hat{y}_{i})^{t} - \\sum_{j \\neq i} y_j^{t} \\Big( 0 -\\hat{y}^{t}_{i} \\Big)\n",
    "\\end{equation} \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} y_j^{t} \\hat{y}^{t}_{i}  -y^{t}_{i}(1 - \\hat{y}_{i})^{t} \n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} y_j^{t} \\hat{y}^{t}_{i}+y^{t}_{i}\\hat{y}_{i}^{t}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "Recall that $\\sum_{j} y_j = 1$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j \\neq i} \\Big( y_j^{t} +y^{t}_{i} \\Big) \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} = \\sum_{j} \\Big( y_j^{t} \\Big) \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "\\end{equation} \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\frac{\\partial{l(o_i^t)}}{\\partial o_{i}^{t}} =  \\hat{y}^{t}_{i}  -y^{t}_{i}\n",
    "}\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets calculate the gradient on the internel nodes $h^t$ from the end of the sequence $\\tau$.\n",
    "<br>\n",
    "I am going to use vector notation here on out. I.e. $h_i^{t}$ becomes $h^t$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^\\tau} L = \\Bigg( \\frac{ \\partial{o^{\\tau}}}\n",
    "{\\partial{h^{\\tau}}} \\Bigg)^{T} \\nabla_{o^\\tau} L\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{h^\\tau} L = V \\nabla_{o^\\tau} L\n",
    "\\end{equation}\n",
    "we iterate backwards through time. Note the dependency of $h^t$ on both $o^t$ and $h^{t+1}$\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = \\Bigg( \\frac{ \\partial{h^{t+1}}}\n",
    "{\\partial{h^{t}}} \\Bigg)^{T} \\nabla_{h^{t+1}} L +\n",
    "\\Bigg( \\frac{ \\partial{o^{t}}}\n",
    "{\\partial{h^{t}}} \\Bigg)^{T} \\nabla_{o^{t}} L \n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivate of the hidden units  w.r.t their previous time step is:\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{ \\partial{h^{t+1}} }\n",
    "{\\partial{h^{t}} }  =  \\frac{ \\partial{h^{t+1}} }{ \\partial{z^{t+1} } }\n",
    "\\frac{ \\partial{z^{t+1} } } { \\partial{h^{t}} }\n",
    "\\end{equation}\n",
    "This leads to:\n",
    "\n",
    "\\begin{equation}\n",
    " \\frac{ \\partial{h^{t+1}} }\n",
    "{\\partial{h^{t}} }  =  diag\\Bigg( \\phi'\\big(z^{t+1}\\big) \\Bigg) W^T\n",
    "\\end{equation}\n",
    "**Note** diag: considering only the leading diagonal values and setting all others to 0. \n",
    "<br><br>\n",
    "For RNNs , we want to use a saturating activation to avoid gradient explosions <br><br>\n",
    "e.g. hyperbolic tagent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = W  diag \\Big( \\phi'\\big(z^{t+1}\\big) \\Big)   \\nabla_{h^{t+1}} L +\n",
    "V \\nabla_{o^{t}} L \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets specify the activation function (using the hyperpolic tagent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{h^t} L = W  diag \\Big( \n",
    "     1 - \\big(h^{t+1}\\big)^2\n",
    "    \\Big)  \\nabla_{h^{t+1}} L +\n",
    "V \\nabla_{o^{t}} L \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the gradients on the biases $b$ and $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{c} L  = \\sum_{t} \\Bigg(\n",
    "     \\frac{\\partial{o^t}}{\\partial{c^t}} \n",
    "     \\Bigg)^{T} \\nabla_{o^t} L\n",
    "\\end{equation}\n",
    "since $\\frac{\\partial{o^t}}{\\partial{c^t}} = 1$\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{c} L  = \\sum_{t} \\nabla_{o^t} L\n",
    "\\end{equation}\n",
    "Next:\n",
    "\\begin{equation}\n",
    "\\nabla_{b} L  = \\sum_{t}  \\Bigg(\n",
    "     \\frac{\\partial{h^t}}{\\partial{b^t}} \n",
    "     \\Bigg)^{T}  \\nabla_{h^t} L\n",
    "\\end{equation}\n",
    "Since $b$ is dependent on h through the activation function $\\phi$, we have: \n",
    "\n",
    "Next:\n",
    "\\begin{equation}\n",
    "\\nabla_{b} L  = \\sum_{t}  diag \\Bigg( \\phi' \\Big( z^t \\Big) \\Bigg) \\nabla_{h^t} L\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative w.r.t to $V$; the hidden-ouput matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{V} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial o_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{V} O_i^{t}\n",
    "\\end{equation}\n",
    "Leading to:\n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{V} L  = \\sum_{t} h^t \\Big(\\nabla_{o^t} L \\Big)^T\n",
    "}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the derivative w.r.t the weight matrices $W$ and $U$, we introduce dummy variables $W^t$ and $U^t$. These are copies of each other at each time step, summing these up will give us the total gradient. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\nabla_{W} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial h_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{W^t} h_i^{t}\n",
    "\\end{equation}\n",
    "giving: \n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{W} L  = \\sum_{t} h^{t-1} \\Big(\\nabla_{h^t} L \\Big)^T  diag \\Bigg( \\phi ' \\big(z^t \\big) \\Bigg)\n",
    "\n",
    "}\n",
    "\\end{equation}\n",
    "for the derivative of w.r.t $U$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{U} L  = \\sum_{t} \\sum_{i}  \\Bigg(\n",
    "    \\frac{ \\partial L}{ \\partial h_{i}^t}\n",
    "     \\Bigg)^T \\nabla_{U^t} h_i^{t}\n",
    "\\end{equation}\n",
    "giving: \n",
    "\\begin{equation}\n",
    "\\boxed{\n",
    "\\nabla_{U} L  = \\sum_{t} x^{t} \\Big( \\nabla_{h^t} L \\Big)^T \n",
    "     diag \\Bigg( \\phi ' \\big(z^t \\big) \\Bigg)\n",
    "\n",
    "}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network implementation with backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, idx2wave):\n",
    "        # network variables \n",
    "        self.idim = input_dim\n",
    "        self.hdim = hidden_dim\n",
    "        self.odim = output_dim\n",
    "        # initialise weights \n",
    "        self.U = np.random.uniform(- np.sqrt(1./self.idim),\n",
    "                                     np.sqrt(1./self.idim),\n",
    "                                    (self.idim, self.hdim) )\n",
    "\n",
    "        self.V = np.random.uniform( -np.sqrt(1./self.hdim),\n",
    "                                     np.sqrt(1./self.hdim), \n",
    "                                    (self.hdim,self.odim))\n",
    "\n",
    "        self.W = np.random.uniform( -np.sqrt(1./self.hdim),\n",
    "                                     np.sqrt(1./self.hdim), \n",
    "                                    (self.hdim,self.hdim))\n",
    "        # bias init \n",
    "        self.b = np.zeros(self.hdim)\n",
    "        self.c = np.zeros(self.odim)\n",
    "\n",
    "        self.idx2wave = idx2wave \n",
    "\n",
    "    def softmax(self,x):\n",
    "        '''\n",
    "        Note that this is a numerically stable version of softmax.\n",
    "        We substract the max value from all elements.\n",
    "        Overflow of a single element, or underflow of all elements,  will render the output usless.\n",
    "        subtracting max leaves only non-positive values ---> no overflow \n",
    "        at least one element = 0 ---> no vanishing denominator (underflow is some enteries is okay) \n",
    "         '''\n",
    "        xt = np.exp(x-np.max(x))\n",
    "        return xt / np.sum(xt)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Single example pass forward, all the way through the network\n",
    "        T = len(x)\n",
    "        # will stack as rows\n",
    "        h = np.zeros((T,self.hdim))\n",
    "        o = np.zeros((T,self.odim))\n",
    "        for t in range(T):\n",
    "            h[t] = self.U.T @ x[t] + self.b\n",
    "            if t > 1:\n",
    "                h[t] += self.W @ h[t-1] + self.b\n",
    "            h[t] = np.tanh(h[t])\n",
    "            o[t] = self.softmax( self.V.T @ h[t] + self.c)\n",
    "        return (o,h)\n",
    "\n",
    "\n",
    "\n",
    "    def backward(self, x, y, clip=None):\n",
    "        T = len(x)\n",
    "        o,h = self.forward(x)\n",
    "        dLdU = np.zeros(self.U.shape)\n",
    "        dLdV = np.zeros(self.V.shape)\n",
    "        dLdW = np.zeros(self.W.shape)\n",
    "        dLdb = np.zeros(self.b.shape)\n",
    "        dLdc = np.zeros(self.c.shape)\n",
    "        # dL/do\n",
    "        delta_o = o\n",
    "        # Notice, only evaluting at last output of network, yHat - y \n",
    "        delta_o[ np.arange(T), y ] -= float(y) \n",
    "        # dL/dh\n",
    "        delta_h = np.zeros((T, self.hdim))\n",
    "        for t in reversed(range(T)):\n",
    "\n",
    "            # collect errors on hidden states\n",
    "            delta_h[t] = self.V @ delta_o[T-1,:]\n",
    "            if t < T-1:\n",
    "                # collect errors on hidden states due to W\n",
    "                delta_h[t] = ( self.W @ np.diag(1-h[t+1]**2) ) @ delta_h[t+1]\n",
    "        for t in range(T):\n",
    "            # error on ouput bias\n",
    "            dLdc += delta_o[T-1,:]\n",
    "            # error on hidden bias \n",
    "            dLdb += (1-h[t]**2) * delta_h[t,:]\n",
    "            # error on hidden-output matrix\n",
    "            ot = delta_o[T-1,:][...,np.newaxis]\n",
    "            ht = h[t,:][...,np.newaxis]\n",
    "            dht = delta_h[t,:][...,np.newaxis]\n",
    "\n",
    "            dLdV += ht @ ot.T \n",
    "            # error on hidden-hidden W\n",
    "            if t > 0 :\n",
    "                h_t = h[t-1,:][...,np.newaxis]\n",
    "                dLdW += ( h_t @ dht.T )@np.diag(1-h[t]**2)\n",
    "            xt = x[t][...,np.newaxis]\n",
    "            dLdU += xt @ dht.T @ np.diag(1-h[t]**2)\n",
    "\n",
    "        if clip is not None:\n",
    "            dLdb = np.clip(dLdb, -clip, clip)\n",
    "            dLdc = np.clip(dLdc, -clip, clip)\n",
    "            dLdV = np.clip(dLdV, -clip, clip)\n",
    "            dLdW = np.clip(dLdW, -clip, clip)\n",
    "            dLdU = np.clip(dLdU, -clip, clip)\n",
    "        return (dLdU, dLdV, dLdW, dLdb, dLdc)\n",
    "\n",
    "\n",
    "    def step(self,x,y,lr=0.0001):\n",
    "        dLdU, dLdV, dLdW, dLdb, dLdc = self.backward(x,y)\n",
    "        self.U -= lr * dLdU\n",
    "        self.V -= lr * dLdV\n",
    "        self.W -= lr * dLdW \n",
    "        self.b -= lr * dLdb \n",
    "        self.c -= lr * dLdc \n",
    "    \n",
    "\n",
    "    def Loss(self, x,y):\n",
    "        o,h = self.forward(x)      \n",
    "        yHat= o[len(x)-1, :]\n",
    "        y_1h = [0.0]*len(yHat)\n",
    "        y_1h[int(y)] = 1.0\n",
    "        LOSS = self.categorical_cross_entropy_loss(yHat, y_1h)\n",
    "        return LOSS\n",
    "\n",
    "\n",
    "    def categorical_cross_entropy_loss(self, yHats, ys):\n",
    "        loss = 0.0\n",
    "        e =  1e-15 # adding to pred values for numerical stability\n",
    "        for pred,true in zip(yHats, ys):\n",
    "            loss += -1.0*(xlogy(true, pred+e) + xlog1py(1.0-true,-pred+e))\n",
    "        return loss\n",
    "\n",
    "    def predict(self,x):\n",
    "        o,_ = self.forward(x)\n",
    "        output = o[len(x)-1, :] \n",
    "        return self.idx2wave(output.index(max(output))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling synthetic time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.linspace(-2*np.pi, 2*np.pi, 50)\n",
    "\n",
    "\n",
    "def noisy_sin_wave(x):\n",
    "    return np.sin(x*0.6) + np.random.normal(loc=0, scale=0.1)\n",
    "\n",
    "\n",
    "def noisy_cos_wave(x):\n",
    "    return np.cos(x*2) + np.random.normal(loc=0, scale=0.5)\n",
    "\n",
    "\n",
    "def noisy_tan_wave(x):\n",
    "    return np.tan(x) + np.random.normal(loc=0, scale=0.3)\n",
    "\n",
    "\n",
    "def plot_noisy_func(func, domain,title):\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.set_title(title)\n",
    "    ax.plot(domain,np.vectorize(func)(domain), \".\")\n",
    "\n",
    "\n",
    "def create_sample_seq(func1, domain, label):\n",
    "    X = np.array([np.vectorize(func1)(domain)])\n",
    "    Y = np.array([label]*X.shape[0])\n",
    "    X = X.T\n",
    "    return X,Y\n",
    "\n",
    "plot_noisy_func(noisy_sin_wave, X, \"Noisy sin wave\")\n",
    "plot_noisy_func(noisy_cos_wave, X, \"Noisy cos wave\")\n",
    "plot_noisy_func(noisy_tan_wave, X, \"Noisy tan wave\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synthetic data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_sin, var_cos, var_tan = sy.symbols(\"sin+e, cos+e, tan+e\")\n",
    "sy.Matrix([var_sin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy.Matrix([var_cos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy.Matrix([var_tan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(domain, sample_size=30):\n",
    "    X0 = [ create_sample_seq(noisy_sin_wave, domain, 0) for _ in range(sample_size)]\n",
    "    X1 = [ create_sample_seq(noisy_cos_wave, domain, 1) for _ in range(sample_size)]\n",
    "    X2 = [ create_sample_seq(noisy_tan_wave, domain, 2) for _ in range(sample_size)]\n",
    "    X = [*X0, *X1 , *X2]\n",
    "    random.shuffle(X)\n",
    "    idx2wave = {0:\"sin\", 1:\"cos\", 2:\"tan\"}\n",
    "    return X, idx2wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8525e041d541f1bd8493f7201aa17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history = []\n",
    "MAX_EPOCHS = 10\n",
    "LR=0.001\n",
    "\n",
    "\n",
    "domain = np.linspace(-2*np.pi, 2*np.pi, 50)\n",
    "X, idx2wave = data_loader(domain)\n",
    "model = RNN(input_dim=1, output_dim=3, hidden_dim=128, idx2wave=idx2wave)\n",
    "for epoch in tqdm(range(MAX_EPOCHS)):\n",
    "    loss = 0\n",
    "    for pair in X:\n",
    "        x,y  = pair        \n",
    "        loss += model.Loss(x, y)\n",
    "        model.step(x, y, lr=LR)\n",
    "        loss = loss / len(x)\n",
    "    print(f\"Epoch {epoch} Loss {loss}\")\n",
    "    loss_history.append(loss)\n",
    "\n",
    "    if loss < 1e-5:\n",
    "        print(f\"Termination condition met at epoch: {epoch}.\")\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/akinwilson/Projects/ground-up/6_from_plane_to_sequential.ipynb Cell 42'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akinwilson/Projects/ground-up/6_from_plane_to_sequential.ipynb#ch0000041?line=0'>1</a>\u001b[0m X, idx2wave \u001b[39m=\u001b[39m data_loader(domain, sample_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/akinwilson/Projects/ground-up/6_from_plane_to_sequential.ipynb#ch0000041?line=1'>2</a>\u001b[0m x, y \u001b[39m=\u001b[39m X[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],X[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m] \n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/akinwilson/Projects/ground-up/6_from_plane_to_sequential.ipynb#ch0000041?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mpredict(x)\n",
      "\u001b[1;32m/home/akinwilson/Projects/ground-up/6_from_plane_to_sequential.ipynb Cell 32'\u001b[0m in \u001b[0;36mRNN.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/akinwilson/Projects/ground-up/6_from_plane_to_sequential.ipynb#ch0000031?line=125'>126</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/akinwilson/Projects/ground-up/6_from_plane_to_sequential.ipynb#ch0000031?line=126'>127</a>\u001b[0m     o,_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(x)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/akinwilson/Projects/ground-up/6_from_plane_to_sequential.ipynb#ch0000031?line=127'>128</a>\u001b[0m     output \u001b[39m=\u001b[39m o[\u001b[39mlen\u001b[39;49m(x), :] \n\u001b[1;32m    <a href='vscode-notebook-cell:/home/akinwilson/Projects/ground-up/6_from_plane_to_sequential.ipynb#ch0000031?line=128'>129</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39midx2wave(output\u001b[39m.\u001b[39mindex(\u001b[39mmax\u001b[39m(output)))\n",
      "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "X, idx2wave = data_loader(domain, sample_size=2)\n",
    "x, y = X[0][0],X[0][1] \n",
    "model.predict(x)\n",
    "\n",
    "\n",
    "# def plot_input(y,domain,title):\n",
    "#     fig, ax = plt.subplots(1,1)\n",
    "#     ax.set_title(title)\n",
    "#     ax.plot(domain,y, \".\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "ground-up-Awl4p5GG",
   "language": "python",
   "name": "ground-up-awl4p5gg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
